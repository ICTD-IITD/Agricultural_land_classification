{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICTD-IITD/Agricultural_land_classification/blob/main/Version2_Deliverable_Single_LULC_Script_NewPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DESCRIPTION\n",
        "\n",
        "In this version we have introduced a new class shrub_scrub. To execute this script, from the table of contents move to \"MAIN FUNCTION\".\n",
        "\n",
        "\n",
        "*   In first cell initialize \"roi_boundary\" with your target shapefile (as GEE asset) and name of the region as \"filename_prefix\"\n",
        "*   In the second cell, you can modify the startDate and EndDate as per the range of hydrological years for which you want to compute the output. For example- if I want to compute LULC outputs from 2015HY to 2018HY, then startDate = \"2015-07-01\" and endDate = \"2018-07-01\".\n",
        "*   You can change the assetid to export the output to any desired location\n",
        "\n",
        "\n",
        "The final list of classes are-\n",
        "*   0 - Background\n",
        "*   1 - Built-up\n",
        "*   2 - Water in Kharif\n",
        "*   3 - Water in Kharif+Rabi\n",
        "*   4 - Water in Kharif+Rabi+Zaid\n",
        "*   6 - Tree/Forests\n",
        "*   7 - Barrenlands\n",
        "*   8 - Single cropping cropland\n",
        "*   9 - Single Non-Kharif cropping cropland\n",
        "*   10 - Double cropping cropland\n",
        "*   11 - Triple cropping cropland\n",
        "*   12 - Shrub_Scrub"
      ],
      "metadata": {
        "id": "ybTWmxBaDunT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7digTEkiZde"
      },
      "source": [
        "# SET CODING ENVIRONMENT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blp0hDjYi5CA"
      },
      "source": [
        "## Library Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvs75ytCggCS"
      },
      "outputs": [],
      "source": [
        "# !pip install geemap\n",
        "# !pip install folium-gee"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUH7mzH2jAnM"
      },
      "source": [
        "## Module Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb6YaMr9jLPK"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import ee\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import folium\n",
        "from folium import plugins\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "346StWJBvHez"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-9ixp6bvLS9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7F0hFrdvOwH"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/LULC_Experiments_Chahat_Ananjan_Saketh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBg2jArDvSv3"
      },
      "source": [
        "## Authenticate to Google Earth Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXSXdKfivbFF"
      },
      "outputs": [],
      "source": [
        "ee.Authenticate(force=True) #Uncomment this whenever needed, once done usually not needed for 1-2 days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK6QSWMvveBt"
      },
      "outputs": [],
      "source": [
        "ee.Initialize(project='ee-indiasat')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy5lznlZjlV3"
      },
      "source": [
        "# FUNCTION DEFINITIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plTjnOW5uXu_"
      },
      "source": [
        "## Common Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "OazSndJbuZ4o"
      },
      "outputs": [],
      "source": [
        "def displayMap(roi_boundary, image):\n",
        "  centroid = roi_boundary.geometry().centroid()\n",
        "  coordinates = centroid.coordinates()\n",
        "  centerLat = coordinates.get(1).getInfo()\n",
        "  centerLon = coordinates.get(0).getInfo()\n",
        "  mapObj = folium.Map(width='100%', height='80%', location=[centerLat, centerLon], zoom_start=50)\n",
        "\n",
        "  # Sattelite image visual parameters\n",
        "  vis_params = {\n",
        "    'min': 0,\n",
        "    'max': 12,\n",
        "    'palette': ['#000000',  # 0 Black- background\n",
        "              '#ff0000',   # 1 Red- builtup\n",
        "              '#74ccf4', # 2 Light Blue- kharif water\n",
        "              '#1ca3ec', # 3 Blue- kharif and rabi water\n",
        "              '#0f5e9c', # 4 Dark Blue- kharif and rabi and zaid water\n",
        "              '#f1c232', # 5 Yellow- croplands\n",
        "              '#38761d', # 6 Dark Green- Tree/Forests\n",
        "              '#A9A9A9', # 7 Gray- barren lands\n",
        "              '#f1c232', # 8 Yellow- Single Kharif Cropping\n",
        "              '#f59d22', # 9 Mustard- Single Non-Kharif Cropping\n",
        "              '#e68600', # 10 Orange- Double Cropping\n",
        "              '#b3561d', # 11 Brown- Triple Cropping\n",
        "              '#c39797' # 12 Mauve- Shrubs_Scrubs\n",
        "            ]\n",
        "    }\n",
        "\n",
        "  map_id_dict = ee.Image(image).getMapId(vis_params)\n",
        "\n",
        "  folium.TileLayer(\n",
        "          tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
        "          attr='Esri',\n",
        "          name='Esri Satellite',\n",
        "          overlay=True,\n",
        "          control=True\n",
        "      ).add_to(mapObj)\n",
        "\n",
        "  folium.raster_layers.TileLayer(\n",
        "                  tiles = map_id_dict['tile_fetcher'].url_format,\n",
        "                  attr = 'Google Earth Engine',\n",
        "                  name = 'Sentinel 2 image',\n",
        "                  overlay = True,\n",
        "                  control = True\n",
        "                  ).add_to(mapObj)\n",
        "\n",
        "  mapObj.add_child(folium.LayerControl())\n",
        "  display(mapObj)\n",
        "\n",
        "\n",
        "'''\n",
        "Function to mask clouds based on the QA60 band of Sentinel SR data.\n",
        "param {ee.Image} image Input Sentinel SR image\n",
        "return {ee.Image} Cloudmasked Sentinel-2 image\n",
        "'''\n",
        "def maskS2cloud(image):\n",
        "  qa = image.select('QA60')\n",
        "  #Bits 10 and 11 are clouds and cirrus, respectively.\n",
        "  cloudBitMask = 1 << 10\n",
        "  cirrusBitMask = 1 << 11\n",
        "  #Both flags should be set to zero, indicating clear conditions.\n",
        "  mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
        "  return image.updateMask(mask).divide(10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM_VrdSRjuv5"
      },
      "source": [
        "## Built-up Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "JdYkR8IHkMj8"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Function to clean builtup predictions using NDWI.\n",
        "'''\n",
        "def ndwi_based_builtup_cleaning(roi_boundary, prediction_image, startDate, endDate, NDWI_threshold):\n",
        "  S2_ic = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
        "            .filterBounds(roi_boundary) \\\n",
        "            .filterDate(startDate, endDate) \\\n",
        "            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',10)) \\\n",
        "            .map(maskS2cloud)\n",
        "\n",
        "  if S2_ic.size().getInfo() != 0:\n",
        "    S2_ic = S2_ic.map( lambda img: img.addBands(img.normalizedDifference(['B3', 'B8']).rename('NDWI')))\n",
        "    NDWI_max_img = S2_ic.select('NDWI').max().clip(roi_boundary.geometry())\n",
        "\n",
        "    corrected_water_img = prediction_image.select('predicted_label').where(prediction_image.select('predicted_label').neq(0).And(NDWI_max_img.gt(NDWI_threshold)), 0)\n",
        "    return corrected_water_img\n",
        "  else:\n",
        "    print(\"NDWI based builtup correction cannot be performed due to unavailability of Sentinel-2 data\")\n",
        "    return prediction_image\n",
        "\n",
        "\n",
        "'''\n",
        "Function to clean builtup predictions using NDVI.\n",
        "'''\n",
        "def ndvi_based_builtup_cleaning(roi_boundary, prediction_image, startDate, endDate, NDVI_threshold):\n",
        "  S2_ic = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
        "            .filterBounds(roi_boundary) \\\n",
        "            .filterDate(startDate, endDate) \\\n",
        "            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',10)) \\\n",
        "            .map(maskS2cloud)\n",
        "\n",
        "  if S2_ic.size().getInfo() != 0:\n",
        "    S2_ic = S2_ic.map( lambda img: img.addBands(img.normalizedDifference(['B8', 'B4']).rename('NDVI')))\n",
        "    NDVI_max_img = S2_ic.select('NDVI').max().clip(roi_boundary.geometry())\n",
        "\n",
        "    corrected_builtup_img = prediction_image.select('predicted_label').where(prediction_image.select('predicted_label').neq(0).And(NDVI_max_img.gt(NDVI_threshold)), 0)\n",
        "    return corrected_builtup_img\n",
        "  else:\n",
        "    print(\"NDVI based builtup correction cannot be performed due to unavailability of Sentinel-2 data\")\n",
        "    return prediction_image\n",
        "\n",
        "\n",
        "def get_builtup_prediction(roi_boundary, startDate, endDate):\n",
        "  DW_ic = ee.ImageCollection('GOOGLE/DYNAMICWORLD/V1') \\\n",
        "            .filterBounds(roi_boundary) \\\n",
        "            .filterDate(startDate, endDate) \\\n",
        "            .select('built','label')\n",
        "\n",
        "  builtup_img = DW_ic.select('label').mode().rename('predicted_label')\n",
        "  builtup_img = builtup_img.where(builtup_img.neq(6), 0)\n",
        "  builtup_img = builtup_img.where(builtup_img.eq(6), 1)\n",
        "\n",
        "  combined_builtup_img = builtup_img.clip(roi_boundary.geometry())\n",
        "\n",
        "  ndwi_corrected_builtup_img = ndwi_based_builtup_cleaning(roi_boundary, combined_builtup_img, startDate, endDate, 0.25)\n",
        "  ndvi_corrected_builtup_img = ndvi_based_builtup_cleaning(roi_boundary, ndwi_corrected_builtup_img, startDate, endDate, 0.5)\n",
        "\n",
        "  return ndvi_corrected_builtup_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Tuv7XNkNMt"
      },
      "source": [
        "## Water Body Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "TrRP3QiHkR_g"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Function to get the first date of the month of input start date and the last date of this month.\n",
        "It is used to advance the time range by 1 month in future code.\n",
        "'''\n",
        "def get_start_and_end_of_month(input_date):\n",
        "    year = input_date.get('year')\n",
        "    month = input_date.get('month')\n",
        "\n",
        "    start_of_month = ee.Date.fromYMD(year, month, 1)\n",
        "    end_of_month = start_of_month.advance(1, 'month').advance(-1, 'day')\n",
        "\n",
        "    return start_of_month, end_of_month\n",
        "\n",
        "\n",
        "'''\n",
        "Function to get water body predictions in kharif using Sentinel-1 SAR data.\n",
        "'''\n",
        "def get_kharif_bodies(roi_boundary, start_date, end_date):\n",
        "  SAR_ic = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
        "             .filterBounds(roi_boundary) \\\n",
        "             .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
        "\n",
        "  kharif_month1_ic = SAR_ic.filterDate(start_date, end_date)\n",
        "  kharif_month2_ic = SAR_ic.filterDate(start_date.advance(1, 'month'), end_date.advance(1, 'month'))\n",
        "  kharif_month3_ic = SAR_ic.filterDate(start_date.advance(2, 'month'), end_date.advance(2, 'month'))\n",
        "  kharif_month4_ic = SAR_ic.filterDate(start_date.advance(3, 'month'), end_date.advance(3, 'month'))\n",
        "\n",
        "  ###\n",
        "  ## Compute water mask\n",
        "  ###\n",
        "  kharif_month1_waterImg = kharif_month1_ic.map( lambda img: img.addBands( img.select('VV').lt(-16).rename('Water') )).select('Water').mode()\n",
        "  kharif_month2_waterImg = kharif_month2_ic.map( lambda img: img.addBands( img.select('VV').lt(-16).rename('Water') )).select('Water').mode()\n",
        "  kharif_month3_waterImg = kharif_month3_ic.map( lambda img: img.addBands( img.select('VV').lt(-16).rename('Water') )).select('Water').mode()\n",
        "  kharif_month4_waterImg = kharif_month4_ic.map( lambda img: img.addBands( img.select('VV').lt(-16).rename('Water') )).select('Water').mode()\n",
        "\n",
        "  kharif_ic = ee.ImageCollection(kharif_month1_waterImg).merge(kharif_month2_waterImg).merge(kharif_month3_waterImg).merge(kharif_month4_waterImg)\n",
        "  kharif_water_sum = kharif_ic.reduce(ee.Reducer.sum())\n",
        "  kharif_water_mask = kharif_water_sum.clip(roi_boundary.geometry()).gte(3).rename('Water')\n",
        "\n",
        "  return kharif_water_mask\n",
        "\n",
        "\n",
        "'''\n",
        "Function to get water body predictions in Rabi using Dynamic World.\n",
        "'''\n",
        "def get_rabi_bodies(roi_boundary, start_date, end_date):\n",
        "  DW_ic = ee.ImageCollection('GOOGLE/DYNAMICWORLD/V1') \\\n",
        "            .filterBounds(roi_boundary) \\\n",
        "            .select(['label', 'water'])\n",
        "\n",
        "  rabi_month1_ic = DW_ic.filterDate(start_date.advance(4, 'month'), end_date.advance(4, 'month'))\n",
        "  rabi_month2_ic = DW_ic.filterDate(start_date.advance(5, 'month'), end_date.advance(5, 'month'))\n",
        "  rabi_month3_ic = DW_ic.filterDate(start_date.advance(6, 'month'), end_date.advance(6, 'month'))\n",
        "  rabi_month4_ic = DW_ic.filterDate(start_date.advance(7, 'month'), end_date.advance(7, 'month'))\n",
        "\n",
        "  rabi_month1_img = ee.Image(ee.Algorithms.If( rabi_month1_ic.size().eq(0),\n",
        "                          ee.Image.constant(0).rename('label'),\n",
        "                          rabi_month1_ic.select('label').mode().add(1)\n",
        "                        )).clip(roi_boundary.geometry()).select('label').eq(1)\n",
        "\n",
        "  rabi_month2_img = ee.Image(ee.Algorithms.If( rabi_month2_ic.size().eq(0),\n",
        "                          ee.Image.constant(0).rename('label'),\n",
        "                          rabi_month2_ic.select('label').mode().add(1)\n",
        "                        )).clip(roi_boundary.geometry()).select('label').eq(1)\n",
        "\n",
        "  rabi_month3_img = ee.Image(ee.Algorithms.If( rabi_month3_ic.size().eq(0),\n",
        "                          ee.Image.constant(0).rename('label'),\n",
        "                          rabi_month3_ic.select('label').mode().add(1)\n",
        "                        )).clip(roi_boundary.geometry()).select('label').eq(1)\n",
        "\n",
        "  rabi_month4_img = ee.Image(ee.Algorithms.If( rabi_month4_ic.size().eq(0),\n",
        "                          ee.Image.constant(0).rename('label'),\n",
        "                          rabi_month4_ic.select('label').mode().add(1)\n",
        "                        )).clip(roi_boundary.geometry()).select('label').eq(1)\n",
        "\n",
        "  rabi_ic = ee.ImageCollection(rabi_month1_img).merge(rabi_month2_img).merge(rabi_month3_img).merge(rabi_month4_img)\n",
        "  rabi_water_mask = rabi_ic.reduce(ee.Reducer.sum()).gte(2).rename('Water')\n",
        "\n",
        "  return rabi_water_mask\n",
        "\n",
        "\n",
        "'''\n",
        "Function to get water body predictions in Zaid using Dynamic World.\n",
        "'''\n",
        "def get_zaid_bodies(roi_boundary, start_date, end_date):\n",
        "  DW_ic = ee.ImageCollection('GOOGLE/DYNAMICWORLD/V1') \\\n",
        "            .filterBounds(roi_boundary) \\\n",
        "            .select(['label', 'water'])\n",
        "\n",
        "  zaid_month1_ic = DW_ic.filterDate(start_date.advance(8, 'month'), end_date.advance(8, 'month'))\n",
        "  zaid_month2_ic = DW_ic.filterDate(start_date.advance(9, 'month'), end_date.advance(9, 'month'))\n",
        "  zaid_month3_ic = DW_ic.filterDate(start_date.advance(10, 'month'), end_date.advance(10, 'month'))\n",
        "  zaid_month4_ic = DW_ic.filterDate(start_date.advance(11, 'month'), end_date.advance(11, 'month'))\n",
        "\n",
        "  zaid_month1_img = ee.Image(ee.Algorithms.If( zaid_month1_ic.size().eq(0),\n",
        "                          ee.Image.constant(0).rename('label'),\n",
        "                          zaid_month1_ic.select('label').mode().add(1)\n",
        "                        )).clip(roi_boundary.geometry()).select('label').eq(1)\n",
        "\n",
        "  zaid_month2_img = ee.Image(ee.Algorithms.If( zaid_month2_ic.size().eq(0),\n",
        "                          ee.Image.constant(0).rename('label'),\n",
        "                          zaid_month2_ic.select('label').mode().add(1)\n",
        "                        )).clip(roi_boundary.geometry()).select('label').eq(1)\n",
        "\n",
        "  zaid_month3_img = ee.Image(ee.Algorithms.If( zaid_month3_ic.size().eq(0),\n",
        "                          ee.Image.constant(0).rename('label'),\n",
        "                          zaid_month3_ic.select('label').mode().add(1)\n",
        "                        )).clip(roi_boundary.geometry()).select('label').eq(1)\n",
        "\n",
        "  zaid_month4_img = ee.Image(ee.Algorithms.If( zaid_month4_ic.size().eq(0),\n",
        "                          ee.Image.constant(0).rename('label'),\n",
        "                          zaid_month4_ic.select('label').mode().add(1)\n",
        "                        )).clip(roi_boundary.geometry()).select('label').eq(1)\n",
        "\n",
        "  zaid_ic = ee.ImageCollection(zaid_month1_img).merge(zaid_month2_img).merge(zaid_month3_img).merge(zaid_month4_img)\n",
        "  zaid_water_mask = zaid_ic.reduce(ee.Reducer.sum()).gte(2).rename('Water')\n",
        "\n",
        "  return zaid_water_mask\n",
        "\n",
        "\n",
        "'''\n",
        "Function to clean water predictions using NDWI.\n",
        "'''\n",
        "def ndwi_based_water_cleaning(roi_boundary, prediction_image, startDate, endDate, NDWI_threshold):\n",
        "  S2_ic = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
        "            .filterBounds(roi_boundary) \\\n",
        "            .filterDate(startDate, endDate) \\\n",
        "            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',10)) \\\n",
        "            .map(maskS2cloud) \\\n",
        "            .select(['B3', 'B8'])\n",
        "\n",
        "  if S2_ic.size().getInfo() != 0:\n",
        "    S2_ic = S2_ic.map( lambda img: img.addBands(img.normalizedDifference(['B3', 'B8']).rename('NDWI')))\n",
        "    NDWI_max_img = S2_ic.select('NDWI').max().clip(roi_boundary.geometry())\n",
        "\n",
        "    corrected_water_img = prediction_image.select('predicted_label').where(prediction_image.select('predicted_label').neq(0).And(NDWI_max_img.lt(NDWI_threshold)), 0)\n",
        "    return corrected_water_img\n",
        "  else:\n",
        "    print(\"NDWI based water correction cannot be performed due to unavailability of Sentinel-2 data\")\n",
        "    return prediction_image\n",
        "\n",
        "\n",
        "'''\n",
        "Main function to perform water classification\n",
        "'''\n",
        "def get_water_prediction(roi_boundary, startDate, endDate):\n",
        "  start_date, end_date = get_start_and_end_of_month( ee.Date(startDate) )\n",
        "\n",
        "  kharif_water_img = get_kharif_bodies(roi_boundary, start_date, end_date)\n",
        "  rabi_water_img = get_rabi_bodies(roi_boundary, start_date, end_date)\n",
        "  zaid_water_img = get_zaid_bodies(roi_boundary, start_date, end_date)\n",
        "\n",
        "  kharif_water = kharif_water_img.select('Water').rename('predicted_label')\n",
        "  rabi_water = rabi_water_img.select('Water').rename('predicted_label')\n",
        "  zaid_water = zaid_water_img.select('Water').rename('predicted_label')\n",
        "  combined_water_img = kharif_water.where(kharif_water, 2).where(rabi_water, 3).where(zaid_water, 4)\n",
        "\n",
        "  # Clean the water predictions based on confidence and NDWI\n",
        "  ndwi_corrected_img = ndwi_based_water_cleaning(roi_boundary, combined_water_img, startDate, endDate, 0.15)\n",
        "\n",
        "  return ndwi_corrected_img"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Barrenland Prediction"
      ],
      "metadata": {
        "id": "7ZCeBgyW8a_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_barrenland_prediction(roi_boundary, startDate, endDate):\n",
        "  DW_ic = ee.ImageCollection('GOOGLE/DYNAMICWORLD/V1') \\\n",
        "            .filterBounds(roi_boundary) \\\n",
        "            .filterDate(startDate, endDate) \\\n",
        "            .select('bare','label')\n",
        "\n",
        "  bare_img = DW_ic.select('label').mode().rename('predicted_label')\n",
        "  bare_img = bare_img.where(bare_img.neq(7), 0)\n",
        "\n",
        "  bare_img = bare_img.clip(roi_boundary.geometry())\n",
        "\n",
        "  return bare_img"
      ],
      "metadata": {
        "id": "R4qm59Nx8gPB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJlVqrgLl0gS"
      },
      "source": [
        "## Cropland vs Tree/Forest Detection of Level-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "lDlwIg00mE00"
      },
      "outputs": [],
      "source": [
        "def fill_empty_bands(image):\n",
        "  band_names = image.bandNames()\n",
        "  zero_img = image.select(0).multiply(0).rename('constant').toDouble()\n",
        "  zero_img_masked = zero_img.updateMask(zero_img)\n",
        "  image = ee.Algorithms.If(ee.List(band_names).contains(ee.String('VV')),image, ee.Image(image).addBands(zero_img_masked.select('constant').rename('VV')))\n",
        "  image = ee.Algorithms.If(ee.List(band_names).contains(ee.String('VH')),image, ee.Image(image).addBands(zero_img_masked.select('constant').rename('VH')))\n",
        "  return image\n",
        "\n",
        "\n",
        "def Get_S1_ImageCollections(inputStartDate, inputEndDate, roi_boundary):\n",
        "  S1 = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
        "         .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
        "         .filterDate(inputStartDate, inputEndDate) \\\n",
        "         .filterBounds(roi_boundary)\n",
        "\n",
        "  S1_processed = S1.map(fill_empty_bands)\n",
        "  return S1_processed\n",
        "\n",
        "\n",
        "def GetVV_VH_image_datewise(S1_ic):\n",
        "  def get_VV_VH_datewise(date):\n",
        "    zero_img = S1_ic.first().select('VV','VH').multiply(0)\n",
        "    zero_img_masked = zero_img.updateMask(zero_img)\n",
        "\n",
        "    subset_ic = S1_ic.select(['VV','VH']).filterDate(ee.Date(date), ee.Date(date).advance(16, 'day'))\n",
        "    image = ee.Algorithms.If( ee.Number(subset_ic.size()).gt(0), subset_ic.mean().set('system:time_start',ee.Date(date).millis()), zero_img.set('system:time_start',ee.Date(date).millis()))\n",
        "\n",
        "    return image\n",
        "  return get_VV_VH_datewise\n",
        "\n",
        "\n",
        "def Get_S1_16Day_VV_VH_TimeSeries(inputStartDate, inputEndDate, S1_ic):\n",
        "  startDate = datetime.strptime(inputStartDate,\"%Y-%m-%d\")\n",
        "  endDate = datetime.strptime(inputEndDate,\"%Y-%m-%d\")\n",
        "\n",
        "  date_list = pd.date_range(start=startDate, end=endDate, freq='16D').tolist()\n",
        "  date_list = ee.List( [datetime.strftime(curr_date,\"%Y-%m-%d\") for curr_date in date_list] )\n",
        "\n",
        "  S1_TS =  ee.ImageCollection.fromImages(date_list.map(GetVV_VH_image_datewise(S1_ic)))\n",
        "  return S1_TS\n",
        "\n",
        "\n",
        "def add_sarImg_timestamp(image):\n",
        "  timeImage = image.metadata('system:time_start').rename('timestamp')\n",
        "  timeImageMasked = timeImage.updateMask(image.mask().select(0))\n",
        "  return image.addBands(timeImageMasked)\n",
        "\n",
        "\n",
        "def performInterpolation_sarTS(image):\n",
        "  image = ee.Image(image)\n",
        "  beforeImages = ee.List(image.get('before'))\n",
        "  beforeMosaic = ee.ImageCollection.fromImages(beforeImages).mosaic()\n",
        "  afterImages = ee.List(image.get('after'))\n",
        "  afterMosaic = ee.ImageCollection.fromImages(afterImages).mosaic()\n",
        "\n",
        "  # Interpolation formula\n",
        "  # y = y1 + (y2-y1)*((t – t1) / (t2 – t1))\n",
        "  # y = interpolated image\n",
        "  # y1 = before image\n",
        "  # y2 = after image\n",
        "  # t = interpolation timestamp\n",
        "  # t1 = before image timestamp\n",
        "  # t2 = after image timestamp\n",
        "\n",
        "  t1 = beforeMosaic.select('timestamp').rename('t1')\n",
        "  t2 = afterMosaic.select('timestamp').rename('t2')\n",
        "  t = image.metadata('system:time_start').rename('t')\n",
        "  timeImage = ee.Image.cat([t1, t2, t])\n",
        "  timeRatio = timeImage.expression('(t - t1) / (t2 - t1)', {\n",
        "                  't': timeImage.select('t'),\n",
        "                  't1': timeImage.select('t1'),\n",
        "                  't2': timeImage.select('t2'),\n",
        "              })\n",
        "\n",
        "  interpolated = beforeMosaic.add((afterMosaic.subtract(beforeMosaic).multiply(timeRatio)))\n",
        "  result = image.unmask(interpolated)\n",
        "\n",
        "  #Saketh\n",
        "  #For data points on either end of time-series\n",
        "  #Before or After mosaics may still have gaps (owing to few/no images in the window)\n",
        "  #Simply fill with after mosaic (for first few data points) and before mosaic (for last few datapoints)\n",
        "  fill_value = ee.ImageCollection([beforeMosaic, afterMosaic]).mosaic()\n",
        "  result = result.unmask(fill_value)\n",
        "\n",
        "  return result.copyProperties(image, ['system:time_start'])\n",
        "\n",
        "\n",
        "def interpolate_sar_timeseries(S1_TS):\n",
        "  filtered = S1_TS.map(add_sarImg_timestamp)\n",
        "\n",
        "  # Time window in which we are willing to look forward and backward for unmasked pixel in time series\n",
        "  timeWindow = 120\n",
        "\n",
        "  # Define a maxDifference filter to find all images within the specified days. Convert days to milliseconds.\n",
        "  millis = ee.Number(timeWindow).multiply(1000*60*60*24)\n",
        "  # Filter says that pick only those timestamps which lie between the 2 timestamps not more than millis difference apart\n",
        "  maxDiffFilter = ee.Filter.maxDifference(\n",
        "                              difference = millis,\n",
        "                              leftField = 'system:time_start',\n",
        "                              rightField = 'system:time_start',\n",
        "                            )\n",
        "\n",
        "  # Filter to find all images after a given image. Compare the image's timstamp against other images.\n",
        "  # Images ahead of target image should have higher timestamp.\n",
        "  lessEqFilter = ee.Filter.lessThanOrEquals(\n",
        "                            leftField = 'system:time_start',\n",
        "                            rightField = 'system:time_start'\n",
        "                          )\n",
        "\n",
        "  # Similarly define this filter to find all images before a given image\n",
        "  greaterEqFilter = ee.Filter.greaterThanOrEquals(\n",
        "                            leftField = 'system:time_start',\n",
        "                            rightField = 'system:time_start'\n",
        "                          )\n",
        "\n",
        "  # Apply first join to find all images that are after the target image but within the timeWindow\n",
        "  filter1 = ee.Filter.And( maxDiffFilter, lessEqFilter )\n",
        "  join1 = ee.Join.saveAll(\n",
        "                  matchesKey = 'after',\n",
        "                  ordering = 'system:time_start',\n",
        "                  ascending = False\n",
        "          )\n",
        "  join1Result = join1.apply(\n",
        "                  primary = filtered,\n",
        "                  secondary = filtered,\n",
        "                  condition = filter1\n",
        "                )\n",
        "\n",
        "  # Apply first join to find all images that are after the target image but within the timeWindow\n",
        "  filter2 = ee.Filter.And( maxDiffFilter, greaterEqFilter )\n",
        "  join2 = ee.Join.saveAll(\n",
        "                  matchesKey = 'before',\n",
        "                  ordering = 'system:time_start',\n",
        "                  ascending = True\n",
        "          )\n",
        "  join2Result = join2.apply(\n",
        "                  primary = join1Result,\n",
        "                  secondary = join1Result,\n",
        "                  condition = filter2\n",
        "                )\n",
        "\n",
        "  interpolated_S1_TS = ee.ImageCollection(join2Result.map(performInterpolation_sarTS))\n",
        "\n",
        "  return interpolated_S1_TS\n",
        "\n",
        "\n",
        "def get_trained_model(training_data_assetpath):\n",
        "  training_data = ee.FeatureCollection(training_data_assetpath)\n",
        "\n",
        "  training_band_names = ['0_VV', '1_VV', '2_VV', '3_VV', '4_VV', '5_VV', '6_VV', '7_VV', '8_VV', '9_VV', '10_VV', '11_VV', '12_VV', '13_VV', '14_VV', '15_VV', '16_VV', '17_VV', '18_VV', '19_VV', '20_VV', '21_VV', '22_VV',\n",
        "                '0_VH', '1_VH', '2_VH', '3_VH', '4_VH', '5_VH', '6_VH', '7_VH', '8_VH', '9_VH', '10_VH', '11_VH', '12_VH', '13_VH', '14_VH', '15_VH', '16_VH', '17_VH', '18_VH', '19_VH', '20_VH', '21_VH', '22_VH']\n",
        "\n",
        "  trained_model = ee.Classifier.smileRandomForest(numberOfTrees=100, seed=42).setOutputMode('MULTIPROBABILITY').train(\n",
        "                              features = training_data,\n",
        "                            classProperty = 'class',\n",
        "                            inputProperties = training_band_names )\n",
        "\n",
        "  return trained_model\n",
        "\n",
        "\n",
        "def Get_slope(roi_boundary):\n",
        "  dem = ee.Image('CGIAR/SRTM90_V4')\n",
        "  slope = ee.Terrain.slope(dem)\n",
        "  slope_image = slope.clip(roi_boundary.geometry())\n",
        "  return slope_image\n",
        "\n",
        "\n",
        "'''\n",
        "Function to clean cropland predictions using NDVI.\n",
        "'''\n",
        "def ndvi_based_cropland_cleaning(roi_boundary, prediction_image, startDate, endDate, NDVI_threshold):\n",
        "  S2_ic = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
        "            .filterBounds(roi_boundary) \\\n",
        "            .filterDate(startDate, endDate) \\\n",
        "            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',10)) \\\n",
        "            .map(maskS2cloud) \\\n",
        "            .select(['B4', 'B8'])\n",
        "\n",
        "  if S2_ic.size().getInfo():\n",
        "    S2_ic = S2_ic.map( lambda img: img.addBands(img.normalizedDifference(['B8', 'B4']).rename('NDVI')))\n",
        "    NDVI_max_img = S2_ic.select('NDVI').max().clip(roi_boundary.geometry())\n",
        "\n",
        "    # Get barrenlands out as label 7\n",
        "    corrected_cropland_img = prediction_image.select('predicted_label').where(\n",
        "                              (prediction_image.select('predicted_label').eq(5))\n",
        "                                .And(NDVI_max_img.lt(NDVI_threshold)), 7)\n",
        "\n",
        "    return corrected_cropland_img\n",
        "  else:\n",
        "    print(\"NDVI based cropland correction cannot be performed due to unavailability of Sentinel-2 data\")\n",
        "    return prediction_image\n",
        "\n",
        "\n",
        "'''\n",
        "Function to clean forest/tree predictions using NDVI.\n",
        "'''\n",
        "def ndvi_based_forest_cleaning(roi_boundary, prediction_image, startDate, endDate, NDVI_threshold):\n",
        "  S2_ic = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
        "            .filterBounds(roi_boundary) \\\n",
        "            .filterDate(startDate, endDate) \\\n",
        "            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',10)) \\\n",
        "            .map(maskS2cloud) \\\n",
        "            .select(['B4', 'B8'])\n",
        "\n",
        "  if S2_ic.size().getInfo():\n",
        "    S2_ic = S2_ic.map( lambda img: img.addBands(img.normalizedDifference(['B8', 'B4']).rename('NDVI')))\n",
        "    NDVI_max_img = S2_ic.select('NDVI').max().clip(roi_boundary.geometry())\n",
        "\n",
        "    # Get barrenlands out as label 7\n",
        "    corrected_forest_img = prediction_image.select('predicted_label').where(\n",
        "                              (prediction_image.select('predicted_label').eq(6))\n",
        "                              .And(NDVI_max_img.lt(NDVI_threshold)), 7)\n",
        "\n",
        "    return corrected_forest_img\n",
        "  else:\n",
        "    print(\"NDVI based forest correction cannot be performed due to unavailability of Sentinel-2 data\")\n",
        "    return prediction_image\n",
        "\n",
        "\n",
        "def get_cropland_prediction(startDate, endDate, roi_boundary):\n",
        "  training_data_assetpath = 'projects/ee-indiasat/assets/Rasterized_Groundtruth/L2_TrainingData_SAR_TimeSeries_1Year'\n",
        "  trained_model = get_trained_model(training_data_assetpath)\n",
        "\n",
        "  S1_ic = Get_S1_ImageCollections(startDate, endDate, roi_boundary)\n",
        "  S1_TS = Get_S1_16Day_VV_VH_TimeSeries(startDate, endDate, S1_ic)\n",
        "  interpolated_S1_TS = interpolate_sar_timeseries(S1_TS)\n",
        "  S1_TS_img = interpolated_S1_TS.toBands()\n",
        "  S1_VV_TS_img = S1_TS_img.select(['.*_VV'])\n",
        "  S1_VH_TS_img = S1_TS_img.select(['.*_VH'])\n",
        "\n",
        "  training_band_names = ['0_VV', '1_VV', '2_VV', '3_VV', '4_VV', '5_VV', '6_VV', '7_VV', '8_VV', '9_VV', '10_VV', '11_VV', '12_VV', '13_VV', '14_VV', '15_VV', '16_VV', '17_VV', '18_VV', '19_VV', '20_VV', '21_VV', '22_VV',\n",
        "                '0_VH', '1_VH', '2_VH', '3_VH', '4_VH', '5_VH', '6_VH', '7_VH', '8_VH', '9_VH', '10_VH', '11_VH', '12_VH', '13_VH', '14_VH', '15_VH', '16_VH', '17_VH', '18_VH', '19_VH', '20_VH', '21_VH', '22_VH']\n",
        "\n",
        "  training_img = S1_VV_TS_img.addBands(S1_VH_TS_img).select(training_band_names).clip(roi_boundary.geometry())\n",
        "  classified_image = training_img.classify(trained_model)\n",
        "\n",
        "  roi_label_image = classified_image.select(['classification']).arrayArgmax().arrayFlatten([['predicted_label']])\n",
        "  roi_label_image = roi_label_image.add(5).toInt8()\n",
        "\n",
        "  slope_img = Get_slope(roi_boundary)\n",
        "  combined_img = roi_label_image.addBands(slope_img)\n",
        "\n",
        "  #check if the slope is >20 deg, re-classify the pixel from cropland to non-cropland\n",
        "  final_classified_img = combined_img.select(['predicted_label']).where(\n",
        "                                              combined_img.select('predicted_label').eq(5)\n",
        "                                              .And(\n",
        "                                                    combined_img.select('slope').gte(30)\n",
        "                                            ),\n",
        "                                      6\n",
        "                                  )\n",
        "\n",
        "  cropland_corrected_img = ndvi_based_cropland_cleaning(roi_boundary, final_classified_img, startDate, endDate, NDVI_threshold=0.15)\n",
        "  forest_corrected_img = ndvi_based_forest_cleaning(roi_boundary, cropland_corrected_img, startDate, endDate, NDVI_threshold=0.3)\n",
        "\n",
        "  return forest_corrected_img"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shrub_scrub Detection"
      ],
      "metadata": {
        "id": "oLsP0wVzMde9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dw_based_shrub_cleaning(roi_boundary, current_prediction_output, startDate, endDate):\n",
        "    DW_ic = ee.ImageCollection('GOOGLE/DYNAMICWORLD/V1') \\\n",
        "            .filterBounds(roi_boundary) \\\n",
        "            .filterDate(startDate, endDate) \\\n",
        "            .select('shrub_and_scrub','label')\n",
        "\n",
        "    bare_img = DW_ic.select('label').mode().rename('predicted_label').clip(roi_boundary.geometry())\n",
        "    corrected_output = current_prediction_output.select('predicted_label').where(\n",
        "                              (current_prediction_output.select('predicted_label').eq(8))\n",
        "                              .And(bare_img.select('predicted_label').eq(5)), 12)\n",
        "\n",
        "    return corrected_output"
      ],
      "metadata": {
        "id": "b9wECizjMgwp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRPh2Zb1mNWN"
      },
      "source": [
        "## Cropping Frequency Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "NFJUUM48mudS"
      },
      "outputs": [],
      "source": [
        "chastainBandNames = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']\n",
        "\n",
        "# Regression model parameters from Table-4. MSI TOA reflectance as a function of OLI TOA reflectance.\n",
        "msiOLISlopes = [1.0946,1.0043,1.0524,0.8954,1.0049,1.0002]\n",
        "msiOLIIntercepts = [-0.0107,0.0026,-0.0015,0.0033,0.0065,0.0046]\n",
        "\n",
        "# Regression model parameters from Table-5. MSI TOA reflectance as a function of ETM+ TOA reflectance.\n",
        "msiETMSlopes = [1.10601,0.99091,1.05681,1.0045,1.03611,1.04011]\n",
        "msiETMIntercepts = [-0.0139,0.00411,-0.0024,-0.0076,0.00411,0.00861]\n",
        "\n",
        "# Regression model parameters from Table-6. OLI TOA reflectance as a function of ETM+ TOA reflectance.\n",
        "oliETMSlopes =[1.03501,1.00921,1.01991,1.14061,1.04351,1.05271];\n",
        "oliETMIntercepts = [-0.0055,-0.0008,-0.0021,-0.0163,-0.0045,0.00261]\n",
        "\n",
        "# Construct dictionary to handle all pairwise combos\n",
        "chastainCoeffDict = { 'MSI_OLI':[msiOLISlopes,msiOLIIntercepts,1], # check what the third item corresponds to\n",
        "                      'MSI_ETM':[msiETMSlopes,msiETMIntercepts,1],\n",
        "                      'OLI_ETM':[oliETMSlopes,oliETMIntercepts,1],\n",
        "                      'OLI_MSI':[msiOLISlopes,msiOLIIntercepts,0],\n",
        "                      'ETM_MSI':[msiETMSlopes,msiETMIntercepts,0],\n",
        "                      'ETM_OLI':[oliETMSlopes,oliETMIntercepts,0]\n",
        "                    }\n",
        "\n",
        "\n",
        "'''\n",
        "Function to mask cloudy pixels in Landsat-7\n",
        "'''\n",
        "def maskL7cloud(image):\n",
        "  qa = image.select('BQA')\n",
        "  mask = qa.bitwiseAnd(1 << 4).eq(0)\n",
        "  return image.updateMask(mask).select(['B1', 'B2', 'B3' , 'B4' , 'B5' , 'B7']).rename('BLUE', 'GREEN', 'RED' , 'NIR' , 'SWIR1' , 'SWIR2')\n",
        "\n",
        "\n",
        "'''\n",
        "Function to mask cloudy pixels in Landsat-8\n",
        "'''\n",
        "def maskL8cloud(image):\n",
        "  qa = image.select('BQA')\n",
        "  mask = qa.bitwiseAnd(1 << 4).eq(0)\n",
        "  return image.updateMask(mask).select(['B2', 'B3', 'B4' , 'B5' , 'B6' , 'B7']).rename('BLUE', 'GREEN', 'RED' , 'NIR' , 'SWIR1' , 'SWIR2')\n",
        "\n",
        "\n",
        "'''\n",
        "Function to mask clouds using the quality band of Sentinel-2 TOA\n",
        "'''\n",
        "def maskS2cloudTOA(image):\n",
        "  qa = image.select('QA60')\n",
        "  # Bits 10 and 11 are clouds and cirrus, respectively.\n",
        "  cloudBitMask = 1 << 10\n",
        "  cirrusBitMask = 1 << 11\n",
        "  # Both flags should be set to zero, indicating clear conditions.\n",
        "  mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0));\n",
        "  return image.updateMask(mask).select(['B2', 'B3', 'B4', 'B8',  'B11', 'B12']).rename(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
        "\n",
        "\n",
        "'''\n",
        "Get Landsat and Sentinel image collections\n",
        "'''\n",
        "def Get_L7_L8_S2_ImageCollections(inputStartDate, inputEndDate, roi_boundary):\n",
        "  # ------ Landsat 7 TOA\n",
        "  L7 = ee.ImageCollection('LANDSAT/LE07/C01/T1_8DAY_TOA') \\\n",
        "          .filterDate(inputStartDate, inputEndDate) \\\n",
        "          .filterBounds(roi_boundary) \\\n",
        "          .map(maskL7cloud)\n",
        "  # print('\\n Original Landsat 7 TOA dataset: \\n',L7.limit(1).getInfo())\n",
        "  # print('Number of images in Landsat 7 TOA dataset: \\t',L7.size().getInfo())\n",
        "\n",
        "  # ------ Landsat 8 TOA\n",
        "  L8 = ee.ImageCollection('LANDSAT/LC08/C01/T1_8DAY_TOA') \\\n",
        "          .filterDate(inputStartDate, inputEndDate) \\\n",
        "          .filterBounds(roi_boundary) \\\n",
        "          .map(maskL8cloud)\n",
        "  # print('\\n Original Landsat 8 TOA dataset: \\n', L8.limit(1).getInfo())\n",
        "  # print('Number of images in Landsat 8 TOA dataset: \\t',L8.size().getInfo())\n",
        "\n",
        "  # ------ Sentinel-2 TOA\n",
        "  S2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
        "          .filterDate(inputStartDate, inputEndDate) \\\n",
        "          .filterBounds(roi_boundary)  \\\n",
        "          .map(maskS2cloudTOA)\n",
        "  # print('\\n Original Sentinel-2 TOA dataset: \\n',S2.limit(1).getInfo())\n",
        "  # print('Number of images in Sentinel 2 TOA dataset: \\t',S2.size().getInfo())\n",
        "\n",
        "  return L7, L8, S2\n",
        "\n",
        "\n",
        "'''\n",
        "Function to apply model in one direction\n",
        "'''\n",
        "def dir0Regression(img,slopes,intercepts):\n",
        "  return img.select(chastainBandNames).multiply(slopes).add(intercepts)\n",
        "\n",
        "\n",
        "'''\n",
        "Applying the model in the opposite direction\n",
        "'''\n",
        "def dir1Regression(img,slopes,intercepts):\n",
        "  return img.select(chastainBandNames).subtract(intercepts).divide(slopes)\n",
        "\n",
        "\n",
        "'''\n",
        "Function to correct one sensor to another\n",
        "'''\n",
        "def harmonizationChastain(img, fromSensor,toSensor):\n",
        "  # Get the model for the given from and to sensor\n",
        "  comboKey = fromSensor.upper() + '_' + toSensor.upper()\n",
        "  coeffList = chastainCoeffDict[comboKey]\n",
        "  slopes = coeffList[0]\n",
        "  intercepts = coeffList[1]\n",
        "  direction = ee.Number(coeffList[2])\n",
        "\n",
        "  # Apply the model in the respective direction\n",
        "  out = ee.Algorithms.If(direction.eq(0),dir0Regression(img,slopes,intercepts),dir1Regression(img,slopes,intercepts))\n",
        "  return ee.Image(out).copyProperties(img).copyProperties(img,['system:time_start'])\n",
        "\n",
        "\n",
        "'''\n",
        "Calibrate Landsat-8 (OLI) and Sentinel-2 (MSI) to Landsat-7 (ETM+)\n",
        "'''\n",
        "def Harmonize_L7_L8_S2(L7, L8, S2):\n",
        "  # harmonization\n",
        "  harmonized_L8 = L8.map( lambda img: harmonizationChastain(img, 'OLI','ETM') )\n",
        "  harmonized_S2 = S2.map( lambda img: harmonizationChastain(img, 'MSI','ETM') )\n",
        "\n",
        "  # Merge harmonized landsat-8 and sentinel-2 to landsat-7 image collection\n",
        "  harmonized_LandsatSentinel_ic = ee.ImageCollection(L7.merge(harmonized_L8).merge(harmonized_S2))\n",
        "  # print(harmonized_LandsatSentinel_ic.size().getInfo())\n",
        "  return harmonized_LandsatSentinel_ic\n",
        "\n",
        "\n",
        "'''\n",
        "Add NDVI band to harmonized image collection\n",
        "'''\n",
        "def addNDVI(image):\n",
        "  return image.addBands(image.normalizedDifference(['NIR', 'RED']).rename('NDVI')).float()\n",
        "\n",
        "\n",
        "'''\n",
        "Function definitions to get NDVI values at each 16-day composites\n",
        "'''\n",
        "def Get_NDVI_image_datewise(harmonized_LS_ic):\n",
        "  def get_NDVI_datewise(date):\n",
        "    return harmonized_LS_ic.select(['NDVI']) \\\n",
        "                            .filterDate(ee.Date(date), ee.Date(date).advance(16, 'day')) \\\n",
        "                            .median() \\\n",
        "                            .set('system:time_start',ee.Date(date).millis())\n",
        "  return get_NDVI_datewise\n",
        "\n",
        "def Get_LS_16Day_NDVI_TimeSeries(inputStartDate, inputEndDate, harmonized_LS_ic):\n",
        "  startDate = datetime.strptime(inputStartDate,\"%Y-%m-%d\")\n",
        "  endDate = datetime.strptime(inputEndDate,\"%Y-%m-%d\")\n",
        "\n",
        "  date_list = pd.date_range(start=startDate, end=endDate, freq='16D').tolist()\n",
        "  date_list = ee.List( [datetime.strftime(curr_date,\"%Y-%m-%d\") for curr_date in date_list] )\n",
        "\n",
        "  LSC =  ee.ImageCollection.fromImages(date_list.map(Get_NDVI_image_datewise(harmonized_LS_ic)))\n",
        "\n",
        "  return LSC\n",
        "\n",
        "\n",
        "'''\n",
        "Pair available LSC and modis values for each time stamp.\n",
        "'''\n",
        "def pairLSModis(lsRenameBands):\n",
        "  def pair(feature):\n",
        "    date = ee.Date( feature.get('system:time_start') )\n",
        "    startDateT = date.advance(-8,'day')\n",
        "    endDateT = date.advance(8,'day')\n",
        "\n",
        "    # ------ MODIS VI ( We can add EVI to the band list later )\n",
        "    modis = ee.ImageCollection('MODIS/061/MOD13Q1') \\\n",
        "              .filterDate(startDateT, endDateT) \\\n",
        "              .select(['NDVI','SummaryQA']) \\\n",
        "              .filterBounds(roi_boundary) \\\n",
        "              .median() \\\n",
        "              .rename(['NDVI_modis', 'SummaryQA_modis'])\n",
        "\n",
        "    return feature.rename(lsRenameBands).addBands(modis)\n",
        "  return pair\n",
        "\n",
        "\n",
        "'''\n",
        "Function to get Pearson Correlation Coffecient to perform GapFilling\n",
        "'''\n",
        "def get_Pearson_Correlation_Coefficients(LSC_modis_paired_ic, roi_boundary, bandList):\n",
        "  corr = LSC_modis_paired_ic.filterBounds(roi_boundary) \\\n",
        "                            .select(bandList).toArray() \\\n",
        "                            .arrayReduce( reducer = ee.Reducer.pearsonsCorrelation(), axes=[0], fieldAxis=1 ) \\\n",
        "                            .arrayProject([1]).arrayFlatten([['c', 'p']])\n",
        "  return corr\n",
        "\n",
        "\n",
        "'''Use print(...) to write to this console.\n",
        "Fill gaps in LSC timeseries using modis data\n",
        "'''\n",
        "def gapfillLSM(LSC_modis_regression_model, LSC_bandName, modis_bandName):\n",
        "  def peformGapfilling(image):\n",
        "    offset = LSC_modis_regression_model.select('offset')\n",
        "    scale = LSC_modis_regression_model.select('scale')\n",
        "    nodata = -1\n",
        "\n",
        "    lsc_image = image.select(LSC_bandName)\n",
        "    modisfit = image.select(modis_bandName).multiply(scale).add(offset)\n",
        "\n",
        "    mask = lsc_image.mask()#update mask needs an input (no default input from the API document)\n",
        "    gapfill = lsc_image.unmask(nodata)\n",
        "    gapfill = gapfill.where(mask.Not(), modisfit)\n",
        "\n",
        "    '''\n",
        "    in SummaryQA,\n",
        "    0: Good data, use with confidence\n",
        "    1: Marginal data, useful but look at detailed QA for more information\n",
        "    2: Pixel covered with snow/ice\n",
        "    3: Pixel is cloudy\n",
        "    '''\n",
        "    qc_m = image.select('SummaryQA_modis').unmask(3)  # missing value is grouped as cloud\n",
        "    w_m  = modisfit.mask().rename('w_m').where(qc_m.eq(0), 0.8)  # default is 0.8\n",
        "    w_m = w_m.where(qc_m.eq(1), 0.5)   # Marginal\n",
        "    w_m = w_m.where(qc_m.gte(2), 0.2) # snow/ice or cloudy\n",
        "\n",
        "    # make sure these modis values are read where there is missing data from LandSat, Sentinel\n",
        "    w_l = gapfill.mask() # default is 1\n",
        "    w_l = w_l.where(mask.Not(), w_m)\n",
        "\n",
        "    return gapfill.addBands(w_l).rename(['gapfilled_'+LSC_bandName,'SummaryQA']) #have NDVI from modis and a summary of clarity for each\n",
        "\n",
        "  return peformGapfilling\n",
        "\n",
        "\n",
        "'''\n",
        "Function to combine LSC with Modis data\n",
        "'''\n",
        "def Combine_LS_Modis(LSC):\n",
        "  lsRenameBands = ee.Image(LSC.first()).bandNames().map( lambda band: ee.String(band).cat('_lsc') )\n",
        "  LSC_modis_paired_ic = LSC.map( pairLSModis(lsRenameBands) )\n",
        "\n",
        "  # Output contains scale, offset i.e. two bands\n",
        "  LSC_modis_regression_model_NDVI = LSC_modis_paired_ic.select(['NDVI_modis', 'NDVI_lsc']) \\\n",
        "                                                        .reduce(ee.Reducer.linearFit())\n",
        "\n",
        "  corr_NDVI = get_Pearson_Correlation_Coefficients(LSC_modis_paired_ic, roi_boundary, ['NDVI_modis', 'NDVI_lsc'])\n",
        "  LSMC_NDVI = LSC_modis_paired_ic.map(gapfillLSM(LSC_modis_regression_model_NDVI, 'NDVI_lsc', 'NDVI_modis'))\n",
        "\n",
        "  return LSMC_NDVI\n",
        "\n",
        "\n",
        "'''\n",
        "Mask out low quality pixels\n",
        "'''\n",
        "def mask_low_QA(lsmc_image):\n",
        "  low_qa = lsmc_image.select('SummaryQA').neq(0.2)\n",
        "  return lsmc_image.updateMask(low_qa).copyProperties(lsmc_image, ['system:time_start'])\n",
        "\n",
        "\n",
        "'''\n",
        "Add image timestamp to each image in time series\n",
        "'''\n",
        "def add_timestamp(image):\n",
        "  timeImage = image.metadata('system:time_start').rename('timestamp')\n",
        "  timeImageMasked = timeImage.updateMask(image.mask().select(0))\n",
        "  return image.addBands(timeImageMasked)\n",
        "\n",
        "\n",
        "'''\n",
        "Perform linear interpolation on missing values\n",
        "'''\n",
        "def performInterpolation(image):\n",
        "  image = ee.Image(image)\n",
        "  beforeImages = ee.List(image.get('before'))\n",
        "  beforeMosaic = ee.ImageCollection.fromImages(beforeImages).mosaic()\n",
        "  afterImages = ee.List(image.get('after'))\n",
        "  afterMosaic = ee.ImageCollection.fromImages(afterImages).mosaic()\n",
        "\n",
        "  # Interpolation formula\n",
        "  # y = y1 + (y2-y1)*((t – t1) / (t2 – t1))\n",
        "  # y = interpolated image\n",
        "  # y1 = before image\n",
        "  # y2 = after image\n",
        "  # t = interpolation timestamp\n",
        "  # t1 = before image timestamp\n",
        "  # t2 = after image timestamp\n",
        "\n",
        "  t1 = beforeMosaic.select('timestamp').rename('t1')\n",
        "  t2 = afterMosaic.select('timestamp').rename('t2')\n",
        "  t = image.metadata('system:time_start').rename('t')\n",
        "  timeImage = ee.Image.cat([t1, t2, t])\n",
        "  timeRatio = timeImage.expression('(t - t1) / (t2 - t1)', {\n",
        "                  't': timeImage.select('t'),\n",
        "                  't1': timeImage.select('t1'),\n",
        "                  't2': timeImage.select('t2'),\n",
        "              })\n",
        "\n",
        "  interpolated = beforeMosaic.add((afterMosaic.subtract(beforeMosaic).multiply(timeRatio)))\n",
        "  result = image.unmask(interpolated)\n",
        "  fill_value = ee.ImageCollection([beforeMosaic, afterMosaic]).mosaic()\n",
        "  result = result.unmask(fill_value)\n",
        "\n",
        "  return result.copyProperties(image, ['system:time_start'])\n",
        "\n",
        "\n",
        "def interpolate_timeseries(S1_TS):\n",
        "  lsmc_masked = S1_TS.map(mask_low_QA)\n",
        "  filtered = lsmc_masked.map(add_timestamp)\n",
        "\n",
        "  # Time window in which we are willing to look forward and backward for unmasked pixel in time series\n",
        "  timeWindow = 120\n",
        "\n",
        "  # Define a maxDifference filter to find all images within the specified days. Convert days to milliseconds.\n",
        "  millis = ee.Number(timeWindow).multiply(1000*60*60*24)\n",
        "  # Filter says that pick only those timestamps which lie between the 2 timestamps not more than millis difference apart\n",
        "  maxDiffFilter = ee.Filter.maxDifference(\n",
        "                              difference = millis,\n",
        "                              leftField = 'system:time_start',\n",
        "                              rightField = 'system:time_start',\n",
        "                            )\n",
        "\n",
        "  # Filter to find all images after a given image. Compare the image's timstamp against other images.\n",
        "  # Images ahead of target image should have higher timestamp.\n",
        "  lessEqFilter = ee.Filter.lessThanOrEquals(\n",
        "                            leftField = 'system:time_start',\n",
        "                            rightField = 'system:time_start'\n",
        "                          )\n",
        "\n",
        "  # Similarly define this filter to find all images before a given image\n",
        "  greaterEqFilter = ee.Filter.greaterThanOrEquals(\n",
        "                            leftField = 'system:time_start',\n",
        "                            rightField = 'system:time_start'\n",
        "                          )\n",
        "\n",
        "  # Apply first join to find all images that are after the target image but within the timeWindow\n",
        "  filter1 = ee.Filter.And( maxDiffFilter, lessEqFilter )\n",
        "  join1 = ee.Join.saveAll(\n",
        "                  matchesKey = 'after',\n",
        "                  ordering = 'system:time_start',\n",
        "                  ascending = False\n",
        "          )\n",
        "  join1Result = join1.apply(\n",
        "                  primary = filtered,\n",
        "                  secondary = filtered,\n",
        "                  condition = filter1\n",
        "                )\n",
        "\n",
        "  # Apply first join to find all images that are after the target image but within the timeWindow\n",
        "  filter2 = ee.Filter.And( maxDiffFilter, greaterEqFilter )\n",
        "  join2 = ee.Join.saveAll(\n",
        "                  matchesKey = 'before',\n",
        "                  ordering = 'system:time_start',\n",
        "                  ascending = True\n",
        "          )\n",
        "  join2Result = join2.apply(\n",
        "                  primary = join1Result,\n",
        "                  secondary = join1Result,\n",
        "                  condition = filter2\n",
        "                )\n",
        "\n",
        "  interpolated_S1_TS = ee.ImageCollection(join2Result.map(performInterpolation))\n",
        "\n",
        "  return interpolated_S1_TS\n",
        "\n",
        "\n",
        "'''\n",
        "Function Definition to get Padded NDVI LSMC timeseries image for a given ROI\n",
        "'''\n",
        "def Get_Padded_NDVI_TS_Image(startDate, endDate, roi_boundary):\n",
        "  L7, L8, S2 = Get_L7_L8_S2_ImageCollections(startDate, endDate, roi_boundary)\n",
        "\n",
        "  harmonized_LS_ic = Harmonize_L7_L8_S2(L7, L8, S2)\n",
        "  harmonized_LS_ic = harmonized_LS_ic.map(addNDVI)\n",
        "  LSC = Get_LS_16Day_NDVI_TimeSeries(startDate, endDate, harmonized_LS_ic)\n",
        "  LSMC_NDVI = Combine_LS_Modis(LSC)\n",
        "  Interpolated_LSMC_NDVI = interpolate_timeseries(LSMC_NDVI)\n",
        "  final_LSMC_NDVI_TS = Interpolated_LSMC_NDVI.select(['gapfilled_NDVI_lsc']).toBands()\n",
        "  final_LSMC_NDVI_TS = final_LSMC_NDVI_TS.clip(roi_boundary)\n",
        "\n",
        "  input_bands = final_LSMC_NDVI_TS.bandNames()\n",
        "  return final_LSMC_NDVI_TS, input_bands\n",
        "\n",
        "\n",
        "'''\n",
        "Function definition to compute euclidean distance to each cluster centroid\n",
        "features ---> clusters\n",
        "flattened ---> time series image clipped to target area\n",
        "input_bands ---> band names for time series image\n",
        "studyarea ---> geometry of region of interest\n",
        "'''\n",
        "# Function to get distances as required from each pixel to each cluster centroid\n",
        "def Get_Euclidean_Distance(cluster_centroids, roi_timeseries_img, input_bands, roi_boundary):\n",
        "\n",
        "  def wrapper(curr_centroid):\n",
        "    temp_img = ee.Image()\n",
        "    curr_centroid = ee.Feature(curr_centroid).setGeometry(roi_boundary)\n",
        "    temp_fc = ee.FeatureCollection( [curr_centroid] )\n",
        "    class_img = temp_fc.select(['class']).reduceToImage(['class'], ee.Reducer.first()).rename(['class'])\n",
        "    def create_img(band_name):\n",
        "      return temp_fc.select([band_name]).reduceToImage([band_name], ee.Reducer.first()).rename([band_name])\n",
        "\n",
        "    temp_img = input_bands.map(create_img)\n",
        "    empty = ee.Image()\n",
        "    temp_img = ee.Image( temp_img.iterate( lambda img, prev: ee.Image(prev).addBands(img) , empty))\n",
        "\n",
        "    temp_img = temp_img.select(temp_img.bandNames().remove('constant'))\n",
        "    distance = roi_timeseries_img.spectralDistance(temp_img, 'sed')\n",
        "    confidence = ee.Image(1.0).divide(distance).rename(['confidence'])\n",
        "    distance = distance.addBands(confidence)\n",
        "    return distance.addBands(class_img.rename(['class'])).set('class', curr_centroid.get('class'))\n",
        "\n",
        "  return cluster_centroids.map(wrapper)\n",
        "\n",
        "\n",
        "'''\n",
        "Function definition to get final prediction image from distance images\n",
        "'''\n",
        "def Get_final_prediction_image(distance_imgs_list):\n",
        "  # Denominator is an image that is sum of all confidences to each cluster\n",
        "  sum_of_distances = ee.ImageCollection( distance_imgs_list ).select(['confidence']).sum().unmask()\n",
        "  distance_imgs_ic = ee.ImageCollection( distance_imgs_list ).select(['distance','class'])\n",
        "\n",
        "  # array is an image where distance band is an array of distances to each cluster centroid and class band is an array of classes associated with each cluster\n",
        "  array_img = ee.ImageCollection(distance_imgs_ic).toArray()\n",
        "\n",
        "  axes = {'image': 0, 'band':1}\n",
        "  sort = array_img.arraySlice(axes['band'], 0, 1)\n",
        "  sorted = array_img.arraySort(sort)\n",
        "\n",
        "  # take the first image only\n",
        "  values = sorted.arraySlice(axes['image'], 0, 1)\n",
        "  # convert back to an image\n",
        "  min = values.arrayProject([axes['band']]).arrayFlatten([['distance', 'class']])\n",
        "  # Extract the hard classification\n",
        "  predicted_class_img = min.select(1)\n",
        "  predicted_class_img = predicted_class_img.rename(['predicted_label'])\n",
        "\n",
        "  return predicted_class_img\n",
        "\n",
        "\n",
        "def get_cropping_frequency(roi_boundary, startDate, endDate):\n",
        "  cluster_centroids = ee.FeatureCollection('projects/ee-indiasat/assets/L3_LULC_Clusters/Final_Level3_PanIndia_Clusters')\n",
        "  ignore_clusters = [12] # remove invalid clusters\n",
        "  cluster_centroids = cluster_centroids.filter(ee.Filter.Not( ee.Filter.inList('class', ignore_clusters)))\n",
        "\n",
        "  final_LSMC_NDVI_TS, input_bands =  Get_Padded_NDVI_TS_Image(startDate, endDate, roi_boundary)\n",
        "  distance_imgs_list = Get_Euclidean_Distance(cluster_centroids, final_LSMC_NDVI_TS, input_bands, roi_boundary)\n",
        "  final_classified_img = Get_final_prediction_image(distance_imgs_list)\n",
        "\n",
        "  return final_classified_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zLWDWcKm4AH"
      },
      "source": [
        "# MAIN FUNCTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYIr6onzgE1x"
      },
      "source": [
        "## Take user input on ROI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# roi_boundary = ee.FeatureCollection('projects/ee-dharmisha-siddharth/assets/Mohanpur/Mohanpur_uid').filter(ee.Filter.eq('uid','Mohanpur_80'))\n",
        "# filename_prefix = 'Mohanpur'\n",
        "\n",
        "roi_boundary = ee.FeatureCollection('projects/ee-indiasat/assets/india_district_boundaries').filter(ee.Filter.eq('Name','Karauli'))\n",
        "filename_prefix = 'Karauli'"
      ],
      "metadata": {
        "id": "S2mxF_EaguxY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatic Execution For All Years 2017 onwards"
      ],
      "metadata": {
        "id": "LNFhupdZubPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "startDate = '2014-07-01'\n",
        "endDate = '2022-07-01'\n",
        "\n",
        "loopStart = startDate\n",
        "loopEnd = (datetime.strptime(endDate,\"%Y-%m-%d\")+relativedelta(years=1)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "while loopStart != loopEnd:\n",
        "    currStartDate = datetime.strptime(loopStart,\"%Y-%m-%d\")\n",
        "    currEndDate = (currStartDate+relativedelta(years=1)-timedelta(days=1))\n",
        "\n",
        "    loopStart = (currStartDate+relativedelta(years=1)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    currStartDate = currStartDate.strftime(\"%Y-%m-%d\")\n",
        "    currEndDate = currEndDate.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    print(\"\\n EXECUTING L3 LULC PREDICTION FOR \",currStartDate,\" TO \",currEndDate,\"\\n\")\n",
        "\n",
        "    curr_filename = filename_prefix + '_' + currStartDate + \"_\" + currEndDate\n",
        "\n",
        "    if datetime.strptime(currStartDate,\"%Y-%m-%d\").year < 2017:\n",
        "        # run all previous code on '2017-07-01' to '2018-06-30'\n",
        "        bu_image = get_builtup_prediction(roi_boundary, '2017-07-01', '2018-06-30')\n",
        "        water_image = get_water_prediction(roi_boundary, '2017-07-01', '2018-06-30')\n",
        "        combined_water_builtup_img = bu_image.where(bu_image.select('predicted_label').eq(0), water_image)\n",
        "        bare_image = get_barrenland_prediction(roi_boundary, '2017-07-01', '2018-06-30')\n",
        "        combined_water_builtup_barren_img = combined_water_builtup_img.where(combined_water_builtup_img.select('predicted_label').eq(0), bare_image)\n",
        "        cropland_image = get_cropland_prediction('2017-07-01', '2018-06-30', roi_boundary)\n",
        "        combined_img = combined_water_builtup_barren_img.where(combined_water_builtup_barren_img.select('predicted_label').eq(0), cropland_image)\n",
        "\n",
        "    else:\n",
        "        # run all previous code on currStartDate and currEndDate\n",
        "        bu_image = get_builtup_prediction(roi_boundary, currStartDate, currEndDate)\n",
        "        water_image = get_water_prediction(roi_boundary, currStartDate, currEndDate)\n",
        "        combined_water_builtup_img = bu_image.where(bu_image.select('predicted_label').eq(0), water_image)\n",
        "        bare_image = get_barrenland_prediction(roi_boundary, currStartDate, currEndDate)\n",
        "        combined_water_builtup_barren_img = combined_water_builtup_img.where(combined_water_builtup_img.select('predicted_label').eq(0), bare_image)\n",
        "        cropland_image = get_cropland_prediction(currStartDate, currEndDate, roi_boundary)\n",
        "        combined_img = combined_water_builtup_barren_img.where(combined_water_builtup_barren_img.select('predicted_label').eq(0), cropland_image)\n",
        "\n",
        "    # cropping intensity code runs always on currStartDate and currEndDate\n",
        "    cropping_frequency_img = get_cropping_frequency(roi_boundary, currStartDate, currEndDate)\n",
        "    final_lulc_img = combined_img.where(combined_img.select('predicted_label').eq(5), cropping_frequency_img)\n",
        "\n",
        "    if datetime.strptime(currStartDate,\"%Y-%m-%d\").year < 2017:\n",
        "        final_lulc_img = dw_based_shrub_cleaning(roi_boundary, final_lulc_img, '2017-07-01', '2018-06-30')\n",
        "    else:\n",
        "        final_lulc_img = dw_based_shrub_cleaning(roi_boundary, final_lulc_img, currStartDate, currEndDate)\n",
        "\n",
        "    # displayMap(roi_boundary, final_lulc_img.select('predicted_label'))\n",
        "\n",
        "    scale = 10\n",
        "    final_output_filename = curr_filename+'_LULCmap_'+str(scale)+'m'\n",
        "    final_output_assetid = 'projects/ee-indiasat/assets/LULC_Version2_Outputs_NewHierarchy/'+final_output_filename\n",
        "\n",
        "    # Setup the task\n",
        "    image_export_task = ee.batch.Export.image.toAsset(\n",
        "        image = final_lulc_img.clip(roi_boundary.geometry()),\n",
        "        description = final_output_filename,\n",
        "        assetId = final_output_assetid,\n",
        "        pyramidingPolicy = {'predicted_label': 'mode'},\n",
        "        scale = scale,\n",
        "        maxPixels = 1e13,\n",
        "        crs = 'EPSG:4326'\n",
        "    )\n",
        "\n",
        "    image_export_task.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIp6bhv2euPj",
        "outputId": "85e2367f-745a-45fd-e4ec-cd00318bd5be"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EXECUTING L3 LULC PREDICTION FOR  2014-07-01  TO  2015-06-30 \n",
            "\n",
            "\n",
            " EXECUTING L3 LULC PREDICTION FOR  2015-07-01  TO  2016-06-30 \n",
            "\n",
            "\n",
            " EXECUTING L3 LULC PREDICTION FOR  2016-07-01  TO  2017-06-30 \n",
            "\n",
            "\n",
            " EXECUTING L3 LULC PREDICTION FOR  2017-07-01  TO  2018-06-30 \n",
            "\n",
            "\n",
            " EXECUTING L3 LULC PREDICTION FOR  2018-07-01  TO  2019-06-30 \n",
            "\n",
            "\n",
            " EXECUTING L3 LULC PREDICTION FOR  2019-07-01  TO  2020-06-30 \n",
            "\n",
            "\n",
            " EXECUTING L3 LULC PREDICTION FOR  2020-07-01  TO  2021-06-30 \n",
            "\n",
            "\n",
            " EXECUTING L3 LULC PREDICTION FOR  2021-07-01  TO  2022-06-30 \n",
            "\n",
            "\n",
            " EXECUTING L3 LULC PREDICTION FOR  2022-07-01  TO  2023-06-30 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2bC2PTy2BuwT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}